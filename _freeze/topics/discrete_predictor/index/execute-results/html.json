{
  "hash": "d27e2622bd83ef0ffad637d08d4eb812",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle:  Palmer penguins and discrete predictors\ndescription: |\n  fitting a model with discrete predictors.\nexecute:\n  freeze: true\nformat:\n  html:\n    code-tools: true\neditor_options: \n  chunk_output_type: console\n---\n\nIn this section we're going to look at a simple model with a single predictor variable which divides the dataset into categories. In this example, categories are treated as \"fixed\" effects. \n\n## Load packages and data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nsuppressPackageStartupMessages(library(brms))\nlibrary(tidybayes)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'tidybayes'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:brms':\n\n    dstudent_t, pstudent_t, qstudent_t, rstudent_t\n```\n\n\n:::\n:::\n\n\n## Data exploration\n\nLet's start by taking a look at the Palmer Penguin dataset, specifically the distribution of observations of bill size.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins |> \n  ggplot(aes(x=bill_dep)) + \n  geom_histogram(binwidth = .5)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_bin()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![Histogram of bill depth for all the penguins in the Palmer Penguin dataset.](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nThere's quite a lot of variation in these measurements, with a suggestion of perhaps more than one peak in this distribution.\n\nThere's also some NA values -- we'll drop them before we move on:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins_noNAbill <- penguins |> \n  drop_na(bill_dep)\n```\n:::\n\n\n\n## A simple model\n\n$$\n\\begin{align}\n\\text{Bill depth} &\\sim \\text{Normal}(\\mu, \\sigma)\\\\\n\\mu &\\sim \\text{Normal}(17, 2) \\\\\n\\sigma &\\sim \\text{Exponential}(1) \\\\\n\\end{align}\n$$\n\nlet's express the same model in brms:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## formula\nbill_bf <- bf(bill_dep ~ 1, family = gaussian())\n## prior\nget_prior(bill_bf, data = penguins_noNAbill)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                   prior     class coef group resp dpar nlpar lb ub tag  source\n student_t(3, 17.3, 2.5) Intercept                                      default\n    student_t(3, 0, 2.5)     sigma                             0        default\n```\n\n\n:::\n\n```{.r .cell-code}\nbill_prior <- c(\n  prior(normal(17, 2), class = \"Intercept\"),\n  prior(exponential(.5), class = \"sigma\", lb = 0)\n)\nbill_prior\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            prior     class coef group resp dpar nlpar   lb   ub tag source\n    normal(17, 2) Intercept                            <NA> <NA>       user\n exponential(0.5)     sigma                               0 <NA>       user\n```\n\n\n:::\n\n```{.r .cell-code}\n## fit\n\nbill_brm <- brm(bill_bf, \n                data = penguins_noNAbill, \n                prior = bill_prior,\n                sample_prior = \"yes\",\n                refresh = 0L,\n                file = here::here(\"topics/discrete_predictor/bill_brm.rds\"), \n                file_refit = \"on_change\")\n\nbill_brm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gaussian \n  Links: mu = identity \nFormula: bill_dep ~ 1 \n   Data: penguins (Number of observations: 342) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept    17.15      0.11    16.94    17.36 1.00     2888     2591\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     1.98      0.08     1.84     2.13 1.00     3354     2693\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\nSome things to notice about the process and results above:\n\n* similar to yesterday's example, we've fit a univariate model to these data. \nHowever, because it is a _gaussian_ model, it requires two parameters: a mean and a standard deviation.\n* although the priors are close to a visual inspection of the histogram, the assumption here is that the prior parameters come from expertise or prior simulations, NOT from looking at the data before modelling! \n* note that we have not tried to drop NA values, but brms has done it on its own and warned us.\n\nWe can use the [`posterior` package](https://mc-stan.org/posterior/) to extract and conveniently summarize the draws from the distribution.  \n\n\n::: {.cell}\n\n```{.r .cell-code}\n## summarize the samples for each parameter into a nice table\nbill_brm |> \n  posterior::summarise_draws() |> \n  knitr::kable()\n```\n\n::: {.cell-output-display}\n\n\n|variable        |        mean|      median|        sd|       mad|           q5|         q95|      rhat| ess_bulk| ess_tail|\n|:---------------|-----------:|-----------:|---------:|---------:|------------:|-----------:|---------:|--------:|--------:|\n|b_Intercept     |   17.150936|   17.150233| 0.1071332| 0.1037355|   16.9752916|   17.328560| 1.0004088| 2888.342| 2590.755|\n|sigma           |    1.978250|    1.975331| 0.0751664| 0.0755603|    1.8587321|    2.107719| 1.0003574| 3354.310| 2692.926|\n|Intercept       |   17.150936|   17.150233| 0.1071332| 0.1037355|   16.9752916|   17.328560| 1.0004088| 2888.342| 2590.755|\n|prior_Intercept |   16.990264|   16.989851| 1.9953338| 2.0734243|   13.7275726|   20.231049| 0.9997240| 3751.547| 3766.682|\n|prior_sigma     |    2.029725|    1.425058| 2.0517451| 1.4376533|    0.1083177|    6.190085| 0.9999286| 3714.513| 3796.457|\n|lprior          |   -3.298640|   -3.296940| 0.0381071| 0.0377788|   -3.3654329|   -3.237870| 1.0006126| 3311.303| 2371.514|\n|lp__            | -721.102922| -720.794259| 1.0160055| 0.7080779| -723.1015945| -720.162162| 1.0032464| 1666.202| 2265.619|\n\n\n:::\n:::\n\n\n\n## Plotting parameters. \n\nWe don't have one value for each of our unknown numbers: we have thousands. \nWe need to get a sense of what these possible values mean scientifically. \nAn excellent way to do this is by making as many pictures as possible. \nWe will start with making plots of specific parameters. \n\nWe can look at the distributions easily using the `bayesplot` package.\n\n\n::: {.cell layout-ncol=\"2\"}\n\n```{.r .cell-code}\nbayesplot::mcmc_hist(bill_brm, pars = \"Intercept\")  + \n  coord_cartesian(xlim = c(15, 20))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code}\nbayesplot::mcmc_hist(bill_brm, pars = \"sigma\") + \n  coord_cartesian(xlim = c(0, 4))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-2.png){width=672}\n:::\n:::\n\n\nNotice that the distributions do not have the same shape as the prior-- this is particularly true for $\\sigma$. \n\n\n::: {.cell layout-ncol=\"2\"}\n\n```{.r .cell-code}\nbayesplot::mcmc_hist(bill_brm, pars = c(\"Intercept\", \"prior_Intercept\"))  + \n  coord_cartesian(xlim = c(10, 25))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n\n```{.r .cell-code}\nbayesplot::mcmc_hist(bill_brm, pars = c(\"sigma\", \"prior_sigma\"))  + \n  coord_cartesian(xlim = c(0, 6))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-2.png){width=672}\n:::\n:::\n\n\n\n\n## Posterior predictions: the easy way to check your model\n\nIn my experience, ecologists (rightly!) care a great deal about model diagnostics. \nAnd with good reason: you need to know how much to trust a model before using it to make a scientific claim. \nBayes offers a straightforward way to show how well a model is doing: plot model predictions, and compare them to the observed data. \nThis involves using the model as a data generating machine, which we'll look at next.\n\n### Pseudocode\n\nHere is the procedure for generating posterior predictions:\n\n* Select some posterior posterior draws. \n* For each draw, extract all the model parameters\n* For each draw, plug the sampled parameters in to the model. Use all the same predictors, factors, etc as the original model.\n* For each draw, draw a random dataset that is the _same size and shape_ as your original data. \n* Overlay the simulated datasets on the observed data.\n\n\n### Posterior prediction in R\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# just get some draws\ndraws_matrix <- posterior::as_draws_matrix(bill_brm)\n\n## set up a matrix. for every posterior sample, \n## (that is, for a value of mu and a value of sigma) \n## draw a whole fake dataset from a normal distribution with that mean and sd. \nnsamples <- 50\nyrep <- matrix(0, ncol = length(penguins_noNAbill$bill_dep), nrow = nsamples)\n\n# pick some random rows\nset.seed(1234)\nchosen_samples <- sample(1:nrow(draws_matrix), \n                         replace = FALSE,\n                         size = nsamples)\n\nsubset_draws <- draws_matrix[chosen_samples,]\n\nfor (r in 1:nsamples){\n yrep[r,] <- rnorm(n = length(penguins_noNAbill$bill_dep), \n                   mean = subset_draws[r, \"Intercept\"], \n                   sd = subset_draws[r, \"sigma\"])\n}\n\nbayesplot::ppc_dens_overlay(y = penguins_noNAbill$bill_dep,\n                            yrep = yrep)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nThis is the manual approach, which demonstrates the entire process explicitly. \nHowever, thanks to the power of brms, this can also be accomplished in a single line:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbrms::pp_check(bill_brm, type = \"dens_overlay\", ndraws = 50)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\n::: {.callout-tip}\n### EXERCISE\nLook at the other graphical posterior predictive checks available in the `bayesplot` package by examining [the vignette](https://mc-stan.org/bayesplot/articles/graphical-ppcs.html). Experiment with some different possibilities for these data.\n:::\n\n\n\nThe posterior predictive distribution gives us a straightfoward way to test our model's performance: \n\n1. we use the model to generate fake observations. \n2. plot these on top of the real data\n3. if the data is a really poor match, we know our model has a distorted view of the world.\n\n## Different groups are different\n\nlet's add in differences among species\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins |> \n  ggplot(aes(x = bill_dep, fill = species))+ \n  geom_histogram(binwidth = .5) + \n  scale_fill_brewer(palette = \"Dark2\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_bin()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nNow we can see that the distribution is probably three different distributions, all placed together. \n\n:::{.callout-warning}\nSometimes scientists will plot histograms of data at the beginning of a research project, and use the histogram to decide if their data are \"normally distributed\" or not. This is not helpful! Instead, decide on a model first, and ask yourself what kind of data you expect.\n:::\n\n## Adding a discrete predictor variable.\n\nHere we extend the model to give each species a different average bill depth. \nHow many parameters are in this model?\n\n$$\n\\begin{align}\n\\text{Bill depth}_{i} &\\sim \\text{Normal}(\\mu_{\\text{species}[i]}, \\sigma) \\\\\n\\mu_{\\text{species}} &\\sim \\text{Normal}(17, 2) \\\\\n\\sigma &\\sim \\text{Exponential}(2) \\\\\n\\end{align}\n$$\n\n::: {.callout-tip collapse=\"true\"}\n## Quick detour : vector indexing\n\nA **very** useful technique, in both R and Stan, is transforming a vector with _indexing_. \nVector indexing requires two vectors: the first contains values we want to select or replicate, the second contains integers giving the positions of the elements we want. For example:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsome_values <- c(\"taco\", \"cat\", \"goat\", \"cheeze\", \"pizza\")\npositions <- c(1,1,2,2,3,1,1,5)\n\nsome_values[positions]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"taco\"  \"taco\"  \"cat\"   \"cat\"   \"goat\"  \"taco\"  \"taco\"  \"pizza\"\n```\n\n\n:::\n:::\n\n\nThis works for number values as well, and is very useful when you want to do simulations! let's simulate three groups with different averages.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(525600)\nsome_means <- c(12, 17, 19)\nsome_labels <- c(\"taco\", \"cat\", \"goat\")\n\ndf_of_means <- data.frame(index = rep(1:3, each = 42)) |> \n  mutate(the_mean = some_means[index],\n         labels = some_labels[index],\n         obs = rnorm(n = length(the_mean),\n                     mean = the_mean,\n                     sd = 1))\n\ndf_of_means |> \n  ggplot(aes(x = obs, fill = labels)) + \n  geom_histogram()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n## Vector indexing in Stan\n\nWe can use this very same technique in Stan: \n\nThe only difference to the previous model is in the line with the for-loop, which is now replaced with a vectorized expression. This is faster to write and will run faster in Stan. However it's not possible in every case.\n\n::: \n\n### Sampling the species model\n\n:::{.callout-tip}\n### EXERCISE\nFit one the species-specific model above using brms. TIP: set the formula to be `bill_dep ~ 0 + species`. \n1. What changes do you need to make to the prior? \n2. Visualize the posterior with `bayesplot`. Does it look better than the model without species? How can you tell?\n:::\n\n::: {.callout-note collapse=\"true\"}\n### SOLUTION\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## formula\nbill_spp_bf <- bf(bill_dep ~ 0 + species, family = gaussian())\n## prior\nget_prior(bill_spp_bf, data = penguins_noNAbill)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                prior class             coef group resp dpar nlpar lb ub tag\n               (flat)     b                                                 \n               (flat)     b    speciesAdelie                                \n               (flat)     b speciesChinstrap                                \n               (flat)     b    speciesGentoo                                \n student_t(3, 0, 2.5) sigma                                         0       \n       source\n      default\n (vectorized)\n (vectorized)\n (vectorized)\n      default\n```\n\n\n:::\n\n```{.r .cell-code}\nbill_spp_prior <- c(\n  prior(normal(17, 2), class = \"b\"),\n  prior(exponential(.5), class = \"sigma\", lb = 0)\n)\nbill_spp_prior\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            prior class coef group resp dpar nlpar   lb   ub tag source\n    normal(17, 2)     b                            <NA> <NA>       user\n exponential(0.5) sigma                               0 <NA>       user\n```\n\n\n:::\n\n```{.r .cell-code}\n## fit\n\nbill_spp_brm <- brm(bill_spp_bf, \n                data = penguins_noNAbill, \n                prior = bill_spp_prior,\n                sample_prior = \"yes\",\n                refresh = 0L,\n                file = here::here(\"topics/discrete_predictor/bill_spp_brm.rds\"), \n                file_refit = \"on_change\")\n\nbill_spp_brm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gaussian \n  Links: mu = identity \nFormula: bill_dep ~ 0 + species \n   Data: penguins_noNAbill (Number of observations: 342) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nspeciesAdelie       18.34      0.09    18.17    18.52 1.00     4590     3481\nspeciesChinstrap    18.41      0.14    18.15    18.69 1.00     4549     3157\nspeciesGentoo       14.99      0.10    14.79    15.19 1.00     4446     3037\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     1.12      0.04     1.04     1.21 1.00     4221     3572\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\nand we can repeat the posterior checking from before:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Posterior predictive check\nbrms::pp_check(bill_spp_brm, type = \"dens_overlay\", ndraws = 50)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n\nThe predicted distribution is now much more like the real data!\n\n:::\n\n\n#### Further questions & challenges\n\n* This model assumes that the $\\sigma$ parameter is the same for all three species. Can you relax that assumption?\n* I recommended that you remove the intercept from the model using `bill_dep ~ 0 + species`. What changes if you put it back in? why?\n\n\n### Visualizing species -- using `tidybayes`\n\nWe can also make figures for each individual species. \nHere we will move away from using `bayesplot` and try to visualize our posterior using the handy functions in the [`tidybayes` package](https://mjskay.github.io/tidybayes/).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidybayes)\n\npenguins_noNAbill |> \n  select(species) |> \n  distinct() |> \n  tidybayes::add_predicted_rvars(bill_spp_brm, ndraws = 100) |> \n  ggplot(aes(xdist = .prediction, y = species, fill = species)) + \n  stat_slab()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\nWe can visualize the uncertainty in predicted values AND in group means :\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrid <- penguins_noNAbill %>%\n  modelr::data_grid(species)\n\nmeans <- grid %>%\n  add_epred_draws(bill_spp_brm)\n\npreds <-  grid %>%\n  add_predicted_draws(bill_spp_brm)\n\npenguins_noNAbill %>%\n  ggplot(aes(y = species, x = bill_dep)) +\n  stat_interval(aes(x = .prediction), data = preds) +\n  stat_pointinterval(aes(x = .epred), data = means, .width = c(.66, .95), position = position_nudge(y = -0.3)) +\n  geom_jitter(height = .05, pch = 21, fill = \"orange\") +\n  scale_color_brewer() + \n  theme_dark()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n\n\n### Exercises\n\n\n#### Level 1\n* repeat this activity for another variable in the dataset. Does the same code work on bill length? What about body size? What would you change about the model (if anything)\n* use bayesplot to examine the fit of body size to these data. \n\n#### Level 2\n* generate some random groups of your own, with known means. How well does the model fit these data\n\n#### Level 3\n* As you can see, the model assumes the same sigma for all species. what if you relax this? \n\n### Optional! \nTry this on your own data! ",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}