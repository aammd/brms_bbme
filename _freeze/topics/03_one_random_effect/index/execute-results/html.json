{
  "hash": "5822f426350ce9bf7012cc3c9edff11f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Models with one level of hierarchy\"\ndescription: |\n  Some of these things are somewhat like the others.\nexecute:\n  freeze: true\ncomments:\n  hypothesis: true\nformat:\n  html:\n    code-tools: true\neditor_options: \n  chunk_output_type: console\n---\n\n\n:::{.callout-tip}\n## Bayesian workflow\n\n1. Visualize your data\n2. Decide on your model structure\n3. Simulate from the model to understand it\n4. Fit the model to the data\n5. Plot model predictions to evaluate the fit / draw conclusions\n:::\n\nToday's goal is to look at a couple of different model structures that we saw yesterday. \n\n## Load packages and data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsuppressPackageStartupMessages(library(dplyr))\nlibrary(ggplot2)\nlibrary(tidyr)\nsuppressPackageStartupMessages(library(brms))\nlibrary(tidybayes)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'tidybayes'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:brms':\n\n    dstudent_t, pstudent_t, qstudent_t, rstudent_t\n```\n\n\n:::\n:::\n\n\n\n## Gaussian random intercepts: Penguin body mass\n\n**Are populations of penguins on different islands different in their body mass?**\n\nThe Palmer penguins are found on three different islands. Let's look at the distribution of body mass of each species on each island.\n\n### Plot the data\n\nFirst a bit of data cleaning and preparation: we select our variables and drop NA values in the predictors^[dropping NA values is not always the best idea! I'm doing it here to create a focused example. Bayes gives us other options for working with missing values, including modelling them directly.].\nWe'll create a new variable out of the union of the species and island names^[again, this is slightly contrived for the sake of making a clean example! normally you'd treat these two variables separately.]\nWe'll also change the units of body mass to kilograms.\nYou can always transform a variable to more sensible units! \n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguin_mass_island <- penguins |> \n  select(species, island, body_mass) |> \n  tidyr::drop_na(body_mass) |> \n  tidyr::unite(sp_island, species, island) |> \n  ## center mass and change the units\n  mutate(mass_kg = (body_mass)/1000)\n\nknitr::kable(head(penguin_mass_island))\n```\n\n::: {.cell-output-display}\n\n\n|sp_island        | body_mass| mass_kg|\n|:----------------|---------:|-------:|\n|Adelie_Torgersen |      3750|   3.750|\n|Adelie_Torgersen |      3800|   3.800|\n|Adelie_Torgersen |      3250|   3.250|\n|Adelie_Torgersen |      3450|   3.450|\n|Adelie_Torgersen |      3650|   3.650|\n|Adelie_Torgersen |      3625|   3.625|\n\n\n:::\n:::\n\n\nLet's visualize the distribution of body sizes for these species+island combinations:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguin_mass_island |> \n  ggplot(aes(y = sp_island,\n             x = mass_kg,\n             colour = sp_island)) + \n  geom_jitter(alpha = 0.8, height = 0.1, width = 0) + \n  scale_color_brewer(palette = \"Dark2\") + \n  labs(x = \"Mass in kg\", y = \"Species_Island\")\n```\n\n::: {.cell-output-display}\n![Observations of the mass of penguins on five different species-island combinations.](index_files/figure-html/gauss-inter-plot-1.png){width=672}\n:::\n:::\n\n\nIt's always good to ask some questions about the dataset. \nHere is a simple one: are the sample sizes equal among the species-island combinations?\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguin_mass_island |> \n  count(sp_island) |> \n  knitr::kable()\n```\n\n::: {.cell-output-display}\n\n\n|sp_island        |   n|\n|:----------------|---:|\n|Adelie_Biscoe    |  44|\n|Adelie_Dream     |  56|\n|Adelie_Torgersen |  51|\n|Chinstrap_Dream  |  68|\n|Gentoo_Biscoe    | 123|\n\n\n:::\n:::\n\n\n### Decide on a model structure\n\nWe'll begin by fitting a model that assumes that body size for each of these five groups is completely independent:\n\n$$\n\\begin{align}\n\\text{Body mass}_i &\\sim \\text{Normal}(\\mu_i, \\sigma_{\\text{obs}}) \\\\\n\\mu_i &= \\bar\\beta + \\beta_{\\text{group}[i]} \\\\\n\\bar\\beta &\\sim \\text{Normal}(5, 2) \\\\\n\\beta_{\\text{group}} &\\sim \\text{Normal}(0, 1) \\\\\n\\sigma_{\\text{obs}} &\\sim \\text{Exponential}(.5)\n\\end{align}\n$$\n\nHere the subscript $i$ is just counting the row of the dataset, and $\\text{group}[i]$ means the group (species+island) to which row number $i$ belongs.\n\n### Simulate to understand this model {#sec-fixed-simulation}\n\nHere's a little trick to get group indexes (numbers) from a character vector:\n\nFirst, make a vector of unique names, then use these to label a numeric vector numbers 1 to $n$, where $n$ is the number of unique names:\n\n::: {.cell}\n\n```{.r .cell-code}\ngroup_names <- unique(penguin_mass_island$sp_island)\ngroup_numbers <- seq_along(group_names)\nnames(group_numbers) <- group_names\n\ngroup_numbers\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAdelie_Torgersen    Adelie_Biscoe     Adelie_Dream    Gentoo_Biscoe \n               1                2                3                4 \n Chinstrap_Dream \n               5 \n```\n\n\n:::\n\n```{.r .cell-code}\ngroup_numbers[\"Adelie_Dream\"]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAdelie_Dream \n           3 \n```\n\n\n:::\n:::\n\n\nNow we have a named vector of sequential numbers, which means we can pull out a number by name.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguin_groupid <- penguin_mass_island |> \n  mutate(group_id = group_numbers[sp_island])\n\nknitr::kable(head(penguin_groupid))\n```\n\n::: {.cell-output-display}\n\n\n|sp_island        | body_mass| mass_kg| group_id|\n|:----------------|---------:|-------:|--------:|\n|Adelie_Torgersen |      3750|   3.750|        1|\n|Adelie_Torgersen |      3800|   3.800|        1|\n|Adelie_Torgersen |      3250|   3.250|        1|\n|Adelie_Torgersen |      3450|   3.450|        1|\n|Adelie_Torgersen |      3650|   3.650|        1|\n|Adelie_Torgersen |      3625|   3.625|        1|\n\n\n:::\n:::\n\n\nAs you can see, we're set up now with the names and the indexes we need. \n\nNow we can simulate data and plot it:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nngroup <- length(group_numbers)\noverall_mean <- rnorm(1, mean = 5, sd = 2)\ngroup_diffs <- rnorm(n = ngroup, mean = 0, sd = 1)\nsigma_obs <- rexp(1, .5)\n\npenguin_pred_obs <- penguin_groupid |> \n  mutate(fake_mass_avg = overall_mean + group_diffs[group_id],\n         fake_mass_obs = rnorm(length(fake_mass_avg), \n                               mean = fake_mass_avg, \n                               sd = sigma_obs))\n\npenguin_pred_obs |> \n  ggplot(aes(y = sp_island,\n             x = fake_mass_obs,\n             colour = sp_island)) + \n  geom_jitter(alpha = 0.8, height = 0.1, width = 0) + \n  scale_color_brewer(palette = \"Dark2\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n:::{.callout-tip}\n### EXERCISE\nRun the above code a few times, trying different prior values. \n:::\n\n### Write it in brms\n\nTo write this out in brms we perform the usual four steps:\n\n1. Identify the data we'll use\n1. define the formula (`bf()`)\n1. define the prior (`get_prior()` and `prior()`)\n1. run the model (`brm()`)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# data\nglimpse(penguin_mass_island)\n\n# formula\nmass_sp_bf <- bf(mass_kg ~ sp_island, family = \"gaussian\")\n\n# prior\n# get_prior(mass_sp_bf, data = penguin_mass_island)\n```\n:::\n\n\nWe have an issue! `brms` is enforcing some naming constraints on our variable names. This is because `brms` does a lot of work for us, and relies on standardized names to know how to handle different kinds of parameters. \n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguin_mass_island_rename <- penguin_mass_island |> \n  rename(SppIsland = sp_island)\n\nglimpse(penguin_mass_island_rename)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 342\nColumns: 3\n$ SppIsland <chr> \"Adelie_Torgersen\", \"Adelie_Torgersen\", \"Adelie_Torgersen\", …\n$ body_mass <int> 3750, 3800, 3250, 3450, 3650, 3625, 4675, 3475, 4250, 3300, …\n$ mass_kg   <dbl> 3.750, 3.800, 3.250, 3.450, 3.650, 3.625, 4.675, 3.475, 4.25…\n```\n\n\n:::\n\n```{.r .cell-code}\n# formula\nmass_sp_bf <- bf(mass_kg ~ SppIsland, family = \"gaussian\")\n\n# prior\nget_prior(mass_sp_bf, data = penguin_mass_island_rename)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                prior     class                      coef group resp dpar nlpar\n               (flat)         b                                                \n               (flat)         b     SppIslandAdelie_Dream                      \n               (flat)         b SppIslandAdelie_Torgersen                      \n               (flat)         b  SppIslandChinstrap_Dream                      \n               (flat)         b    SppIslandGentoo_Biscoe                      \n student_t(3, 4, 2.5) Intercept                                                \n student_t(3, 0, 2.5)     sigma                                                \n lb ub tag       source\n                default\n           (vectorized)\n           (vectorized)\n           (vectorized)\n           (vectorized)\n                default\n  0             default\n```\n\n\n:::\n\n```{.r .cell-code}\npeng_mass_prior <- c(\n  prior(normal(5, 2), class = \"Intercept\"),\n  prior(normal(0, 1), class = \"b\"),\n  prior(exponential(.5), class = \"sigma\", lb = 0)\n)\n```\n:::\n\n\nWe have two choices here. We could use the trick of removing the model intercept. \nThis makes it simpler to set a prior, since we're setting the prior on means and not on one mean and several differences.\nHowever, in our simulation we modelled an overall average and a difference to different\n\n\n::: {.cell}\n\n```{.r .cell-code}\npeng_mass_prior_brm <- brm(\n  formula = mass_sp_bf, \n  data = penguin_mass_island_rename,\n  prior = peng_mass_prior,\n  sample_prior = \"only\",\n  file = here::here(\"topics/03_one_random_effect/peng_mass_prior_brm.rds\"),\n  file_refit = \"on_change\",\n  refresh = 0L)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCompiling Stan program...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nTrying to compile a simple C file\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRunning /usr/lib/R/bin/R CMD SHLIB foo.c\nusing C compiler: ‘gcc (Ubuntu 11.4.0-1ubuntu1~22.04.2) 11.4.0’\ngcc -I\"/usr/share/R/include\" -DNDEBUG   -I\"/home/andrew/R/x86_64-pc-linux-gnu-library/4.5/Rcpp/include/\"  -I\"/home/andrew/R/x86_64-pc-linux-gnu-library/4.5/RcppEigen/include/\"  -I\"/home/andrew/R/x86_64-pc-linux-gnu-library/4.5/RcppEigen/include/unsupported\"  -I\"/home/andrew/R/x86_64-pc-linux-gnu-library/4.5/BH/include\" -I\"/home/andrew/R/x86_64-pc-linux-gnu-library/4.5/StanHeaders/include/src/\"  -I\"/home/andrew/R/x86_64-pc-linux-gnu-library/4.5/StanHeaders/include/\"  -I\"/home/andrew/R/x86_64-pc-linux-gnu-library/4.5/RcppParallel/include/\"  -I\"/home/andrew/R/x86_64-pc-linux-gnu-library/4.5/rstan/include\" -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DUSE_STANC3 -DSTRICT_R_HEADERS  -DBOOST_PHOENIX_NO_VARIADIC_EXPRESSION  -D_HAS_AUTO_PTR_ETC=0  -include '/home/andrew/R/x86_64-pc-linux-gnu-library/4.5/StanHeaders/include/stan/math/prim/fun/Eigen.hpp'  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1       -fpic  -g -O2 -ffile-prefix-map=/build/r-base-xupQTd/r-base-4.5.2=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c foo.c -o foo.o\nIn file included from /home/andrew/R/x86_64-pc-linux-gnu-library/4.5/RcppEigen/include/Eigen/Core:19,\n                 from /home/andrew/R/x86_64-pc-linux-gnu-library/4.5/RcppEigen/include/Eigen/Dense:1,\n                 from /home/andrew/R/x86_64-pc-linux-gnu-library/4.5/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22,\n                 from <command-line>:\n/home/andrew/R/x86_64-pc-linux-gnu-library/4.5/RcppEigen/include/Eigen/src/Core/util/Macros.h:679:10: fatal error: cmath: No such file or directory\n  679 | #include <cmath>\n      |          ^~~~~~~\ncompilation terminated.\nmake: *** [/usr/lib/R/etc/Makeconf:202: foo.o] Error 1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nStart sampling\n```\n\n\n:::\n:::\n\n\nlet's look at the model summary\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(peng_mass_prior_brm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gaussian \n  Links: mu = identity \nFormula: mass_kg ~ SppIsland \n   Data: penguin_mass_island_rename (Number of observations: 342) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n                          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept                     5.02      2.05     1.05     8.92 1.00     4374\nSppIslandAdelie_Dream         0.00      1.00    -2.04     1.96 1.00     4693\nSppIslandAdelie_Torgersen    -0.00      1.02    -2.05     2.00 1.00     5574\nSppIslandChinstrap_Dream      0.01      0.99    -1.96     1.97 1.00     5188\nSppIslandGentoo_Biscoe       -0.02      0.99    -1.95     1.97 1.00     5383\n                          Tail_ESS\nIntercept                     2710\nSppIslandAdelie_Dream         2681\nSppIslandAdelie_Torgersen     3241\nSppIslandChinstrap_Dream      2799\nSppIslandGentoo_Biscoe        3046\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     2.02      2.03     0.06     7.39 1.00     3152     1885\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\nAs you can see, the values are close to the ones we set in the prior. let's look at model predictions as we've done before\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguin_mass_island_rename |> \n  tidybayes::add_predicted_draws(peng_mass_prior_brm, ndraws = 6) |> \n  ggplot(aes(x = .prediction, y = SppIsland)) + \n  geom_point() + \n  facet_wrap(~.draw)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nvery encouraging! These distributions show some variation, but are loosely within the range of the possible.\n\n### Fit the model\n\nFitting the model now is simple, we only need to change the `sample_prior` argument.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npeng_mass_brm <- brm(\n  formula = mass_sp_bf, \n  data = penguin_mass_island_rename,\n  prior = peng_mass_prior,\n  sample_prior = \"yes\",\n  file = here::here(\"topics/03_one_random_effect/peng_mass_brm.rds\"),\n  file_refit = \"on_change\",\n  refresh = 0L)\n\nsummary(peng_mass_brm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gaussian \n  Links: mu = identity \nFormula: mass_kg ~ SppIsland \n   Data: penguin_mass_island_rename (Number of observations: 342) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n                          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept                     3.71      0.07     3.58     3.85 1.00     1848\nSppIslandAdelie_Dream        -0.03      0.09    -0.21     0.16 1.00     2136\nSppIslandAdelie_Torgersen    -0.01      0.09    -0.19     0.17 1.00     2287\nSppIslandChinstrap_Dream      0.02      0.09    -0.16     0.19 1.00     2112\nSppIslandGentoo_Biscoe        1.36      0.08     1.20     1.52 1.00     2000\n                          Tail_ESS\nIntercept                     2203\nSppIslandAdelie_Dream         2783\nSppIslandAdelie_Torgersen     2697\nSppIslandChinstrap_Dream      2582\nSppIslandGentoo_Biscoe        2636\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.47      0.02     0.43     0.50 1.00     4055     2757\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\n### Plot predictions to evaluate results\n\nLet's begin by plotting the averages for each group.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# first look for the variable names in this model\nget_variables(peng_mass_brm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"b_Intercept\"                 \"b_SppIslandAdelie_Dream\"    \n [3] \"b_SppIslandAdelie_Torgersen\" \"b_SppIslandChinstrap_Dream\" \n [5] \"b_SppIslandGentoo_Biscoe\"    \"sigma\"                      \n [7] \"Intercept\"                   \"prior_Intercept\"            \n [9] \"prior_b\"                     \"prior_sigma\"                \n[11] \"lprior\"                      \"lp__\"                       \n[13] \"accept_stat__\"               \"stepsize__\"                 \n[15] \"treedepth__\"                 \"n_leapfrog__\"               \n[17] \"divergent__\"                 \"energy__\"                   \n```\n\n\n:::\n\n```{.r .cell-code}\npenguin_predicted_avgs <- penguin_mass_island_rename |> \n  select(SppIsland) |> \n  distinct() |> \n  tidybayes::add_epred_rvars(peng_mass_brm)\n\npenguin_predicted_avgs |> \n  ggplot(aes(xdist = .epred, y = SppIsland)) + \n  stat_dist_halfeye()+\n  geom_point(aes(x = mass_kg, y = SppIsland), \n             data = penguin_mass_island_rename, \n             position = position_jitter(height = .1), \n             col = \"orange\",\n             inherit.aes = FALSE)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n\nSome things to notice about the code above: \n\n* We use `tidybayes::stat_dist_halfeye()` to summarize the posterior distribution.\n* we're adding points from the original data (`penguin_mass_island`) with `geom_jitter()`. We're adding noise vertically to make the visualization better, but not adding any horizontal noise.\n\n:::{.callout-tip}\n### EXERCISE: plot posterior predictions of _observations_\n\nRepeat the exercise above using predicted ***observations***, rather than the expected values for each group. \nWhy are the results different? What additional error is included in these predictions?\n:::\n\n:::{.callout-note collapse=\"true\"}\n### SOLUTION\n\nPlotting predicted values requires a change in two places: \n\n1. changing from `tidybayes::add_predicted_rvars` to `tidybayes::add_predicted_rvars`\n2. editing the ggplot2 code to use `.prediction` rather than `.epred`\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguin_predicted_avgs <- penguin_mass_island_rename |> \n  select(SppIsland) |> \n  distinct() |> \n  tidybayes::add_predicted_rvars(peng_mass_brm)\n\npenguin_predicted_avgs |> \n  ggplot(aes(xdist = .prediction, y = SppIsland)) + \n  stat_dist_halfeye()+\n  geom_point(aes(x = mass_kg, y = SppIsland), \n             data = penguin_mass_island_rename, \n             position = position_jitter(height = .1), \n             col = \"orange\",\n             inherit.aes = FALSE)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n:::\n\n### Make it hierarchical\n\n#### Math\n\n\n:::{.column-screen}\n\n::::{.columns}\n\n::: {.column width=\"2.5%\"}\n:::\n\n::: {.column width=\"45%\"}\n$$\n\\begin{align}\n\\text{Body mass}_i &\\sim \\text{Normal}(\\mu_i, \\sigma_{\\text{obs}}) \\\\\n\\mu_i &= \\bar\\beta + \\beta_{\\text{group}[i]} \\\\\n\\bar\\beta &\\sim \\text{Normal}(5, 2) \\\\\n\\beta_{\\text{group}} &\\sim \\text{Normal}(0, 1) \\\\\n\\sigma_{\\text{obs}} &\\sim \\text{Exponential}(.5)\n\\end{align}\n$$\n:::\n\n::: {.column width=\"5%\"}\n\n:::\n\n::: {.column width=\"45%\"}\n$$\n\\begin{align}\n\\text{Body mass}_i &\\sim \\text{Normal}(\\mu_i, \\sigma_{\\text{obs}}) \\\\\n\\mu_i &= \\bar\\beta + \\beta_{\\text{group}[i]} \\\\\n\\bar\\beta &\\sim \\text{Normal}(5, 2) \\\\\n\\beta_{\\text{group}} &\\sim \\text{Normal}(0, \\sigma_{\\text{sp}}) \\\\\n\\sigma_{\\text{obs}} &\\sim \\text{Exponential}(.5) \\\\\n\\sigma_{\\text{sp}} &\\sim \\text{Exponential}(1)\n\\end{align}\n$$\n\n:::\n\n::: {.column width=\"2.5%\"}\n\n:::\n\n::::\n\n:::\n\n### Syntax for a Hierarchical model in `brms`\n\n`brms` uses the familiar lme4 formula syntax to specify a random effect. So the model above goes from \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# formula\nmass_sp_bf <- bf(mass_kg ~ 1 + SppIsland, family = \"gaussian\")\n```\n:::\n\n\nto the following \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# formula\nmass_sp_bf <- bf(mass_kg ~ 1 + (1|SppIsland), family = \"gaussian\")\n```\n:::\n\n\n\n### Simulation of a hierarchical model in R \n\n:::{.callout-tip}\n### EXERCISE \nSimulate from the hierarchical model above. Base your approach on the [code for simulation the non-hierarchical version](#sec-fixed-simulation) \nRemember to simulate one additional number: the standard deviation of group differences\nAlternatively, attempt to simulate it using brms.\n:::\n\n:::{.callout-note collapse=\"true\"}\n### SOLUTION\n\nSimulation via R: \n\n\n::: {.cell}\n\n```{.r .cell-code}\nngroup <- length(group_numbers)\noverall_mean <- rnorm(1, mean = 5, sd = 2)\nsigma_group <- rexp(1, .1)\ngroup_diffs <- rnorm(n = ngroup, mean = 0, sd = sigma_group)\nsigma_obs <- rexp(1, .5)\n\npenguin_pred_obs <- penguin_groupid |> \n  mutate(fake_mass_avg = overall_mean + group_diffs[group_id],\n         fake_mass_obs = rnorm(length(fake_mass_avg), \n                               mean = fake_mass_avg, \n                               sd = sigma_obs))\n\npenguin_pred_obs |> \n  ggplot(aes(y = sp_island,\n             x = fake_mass_obs,\n             colour = sp_island)) + \n  geom_jitter(alpha = 0.8, height = 0.1, width = 0) + \n  scale_color_brewer(palette = \"Dark2\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\nSimulation via brms:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(penguin_mass_island_rename)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 342\nColumns: 3\n$ SppIsland <chr> \"Adelie_Torgersen\", \"Adelie_Torgersen\", \"Adelie_Torgersen\", …\n$ body_mass <int> 3750, 3800, 3250, 3450, 3650, 3625, 4675, 3475, 4250, 3300, …\n$ mass_kg   <dbl> 3.750, 3.800, 3.250, 3.450, 3.650, 3.625, 4.675, 3.475, 4.25…\n```\n\n\n:::\n\n```{.r .cell-code}\n# formula\nmass_hier_bf <- bf(mass_kg ~ 1 + (1|SppIsland), family = \"gaussian\")\n\n# prior\nget_prior(mass_hier_bf, data = penguin_mass_island_rename)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                prior     class      coef     group resp dpar nlpar lb ub tag\n student_t(3, 4, 2.5) Intercept                                              \n student_t(3, 0, 2.5)        sd                                      0       \n student_t(3, 0, 2.5)        sd           SppIsland                  0       \n student_t(3, 0, 2.5)        sd Intercept SppIsland                  0       \n student_t(3, 0, 2.5)     sigma                                      0       \n       source\n      default\n      default\n (vectorized)\n (vectorized)\n      default\n```\n\n\n:::\n\n```{.r .cell-code}\npeng_mass_hier_prior <- c(\n  prior(normal(5, 2), class = \"Intercept\"),\n  prior(exponential(1), class = \"sd\", lb = 0),\n  prior(exponential(1), class = \"sigma\", lb = 0)\n)\n\npeng_mass_prior_brm <- brm(\n  formula = mass_hier_bf, \n  data = penguin_mass_island_rename,\n  prior = peng_mass_hier_prior,\n  sample_prior = \"only\",\n  file = here::here(\"topics/03_one_random_effect/peng_mass_prior_brm.rds\"),\n  file_refit = \"on_change\",\n  refresh = 0L)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCompiling Stan program...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nTrying to compile a simple C file\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRunning /usr/lib/R/bin/R CMD SHLIB foo.c\nusing C compiler: ‘gcc (Ubuntu 11.4.0-1ubuntu1~22.04.2) 11.4.0’\ngcc -I\"/usr/share/R/include\" -DNDEBUG   -I\"/home/andrew/R/x86_64-pc-linux-gnu-library/4.5/Rcpp/include/\"  -I\"/home/andrew/R/x86_64-pc-linux-gnu-library/4.5/RcppEigen/include/\"  -I\"/home/andrew/R/x86_64-pc-linux-gnu-library/4.5/RcppEigen/include/unsupported\"  -I\"/home/andrew/R/x86_64-pc-linux-gnu-library/4.5/BH/include\" -I\"/home/andrew/R/x86_64-pc-linux-gnu-library/4.5/StanHeaders/include/src/\"  -I\"/home/andrew/R/x86_64-pc-linux-gnu-library/4.5/StanHeaders/include/\"  -I\"/home/andrew/R/x86_64-pc-linux-gnu-library/4.5/RcppParallel/include/\"  -I\"/home/andrew/R/x86_64-pc-linux-gnu-library/4.5/rstan/include\" -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DUSE_STANC3 -DSTRICT_R_HEADERS  -DBOOST_PHOENIX_NO_VARIADIC_EXPRESSION  -D_HAS_AUTO_PTR_ETC=0  -include '/home/andrew/R/x86_64-pc-linux-gnu-library/4.5/StanHeaders/include/stan/math/prim/fun/Eigen.hpp'  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1       -fpic  -g -O2 -ffile-prefix-map=/build/r-base-xupQTd/r-base-4.5.2=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c foo.c -o foo.o\nIn file included from /home/andrew/R/x86_64-pc-linux-gnu-library/4.5/RcppEigen/include/Eigen/Core:19,\n                 from /home/andrew/R/x86_64-pc-linux-gnu-library/4.5/RcppEigen/include/Eigen/Dense:1,\n                 from /home/andrew/R/x86_64-pc-linux-gnu-library/4.5/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22,\n                 from <command-line>:\n/home/andrew/R/x86_64-pc-linux-gnu-library/4.5/RcppEigen/include/Eigen/src/Core/util/Macros.h:679:10: fatal error: cmath: No such file or directory\n  679 | #include <cmath>\n      |          ^~~~~~~\ncompilation terminated.\nmake: *** [/usr/lib/R/etc/Makeconf:202: foo.o] Error 1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nStart sampling\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(peng_mass_prior_brm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gaussian \n  Links: mu = identity \nFormula: mass_kg ~ 1 + (1 | SppIsland) \n   Data: penguin_mass_island_rename (Number of observations: 342) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nMultilevel Hyperparameters:\n~SppIsland (Number of levels: 5) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.98      0.96     0.03     3.58 1.00     4674     2545\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     4.99      1.93     1.33     8.77 1.00     6423     3014\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     1.00      1.02     0.03     3.83 1.00     3434     1599\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\n\n:::\n\n## Fitting the model in brms\n\n\n::: {.cell}\n\n```{.r .cell-code}\npeng_mass_hier_brm <- brm(\n  formula = mass_hier_bf, \n  data = penguin_mass_island_rename,\n  prior = peng_mass_hier_prior,\n  sample_prior = \"yes\",\n  file = here::here(\"topics/03_one_random_effect/peng_mass_hier_brm.rds\"),\n  file_refit = \"on_change\",\n  refresh = 0L)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(peng_mass_hier_brm)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: There were 4 divergent transitions after warmup. Increasing\nadapt_delta above 0.8 may help. See\nhttp://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gaussian \n  Links: mu = identity \nFormula: mass_kg ~ 1 + (1 | SppIsland) \n   Data: penguin_mass_island_rename (Number of observations: 342) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nMultilevel Hyperparameters:\n~SppIsland (Number of levels: 5) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.74      0.29     0.38     1.47 1.00      808     1346\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     4.04      0.36     3.32     4.80 1.01      683      696\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.47      0.02     0.43     0.50 1.00     2225     1955\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidybayes::get_variables(peng_mass_hier_brm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"b_Intercept\"                            \n [2] \"sd_SppIsland__Intercept\"                \n [3] \"sigma\"                                  \n [4] \"Intercept\"                              \n [5] \"r_SppIsland[Adelie_Biscoe,Intercept]\"   \n [6] \"r_SppIsland[Adelie_Dream,Intercept]\"    \n [7] \"r_SppIsland[Adelie_Torgersen,Intercept]\"\n [8] \"r_SppIsland[Chinstrap_Dream,Intercept]\" \n [9] \"r_SppIsland[Gentoo_Biscoe,Intercept]\"   \n[10] \"prior_Intercept\"                        \n[11] \"prior_sigma\"                            \n[12] \"prior_sd_SppIsland\"                     \n[13] \"lprior\"                                 \n[14] \"lp__\"                                   \n[15] \"accept_stat__\"                          \n[16] \"stepsize__\"                             \n[17] \"treedepth__\"                            \n[18] \"n_leapfrog__\"                           \n[19] \"divergent__\"                            \n[20] \"energy__\"                               \n```\n\n\n:::\n\n```{.r .cell-code}\nbayesplot::mcmc_areas(peng_mass_hier_brm,\n                      pars = c(\"sd_SppIsland__Intercept\", \"prior_sd_SppIsland\"))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n\n### Diagnostics\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# get info on the sampler\nlp_peng <- log_posterior(peng_mass_hier_brm)\nnp_peng <- nuts_params(peng_mass_hier_brm)\nposterior_hier <- as.array(peng_mass_hier_brm)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbayesplot::color_scheme_set(\"darkgray\")\nbayesplot::mcmc_parcoord(posterior_hier, np = np_peng) +  \n  # coord_flip() + \n  coord_cartesian(ylim = c(-2, 10)) + \n  NULL\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\nWe can look at divergent iterations in two dimensions here:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbayesplot::mcmc_pairs(posterior_hier,\n           np = np_peng, \n           pars = c(\"sd_SppIsland__Intercept\",\"b_Intercept\",\"sigma\"),\n           off_diag_args = list(size = 0.75))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbayesplot::mcmc_trace(posterior_hier, pars = \"sd_SppIsland__Intercept\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbayesplot::mcmc_trace(posterior_hier, pars = \"b_Intercept\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\n\n### Sample for a new group\n\nWe can make predictions in the same way that we did previously:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguin_predicted_hier_avgs <- penguin_mass_island_rename |> \n  select(SppIsland) |> \n  distinct() |> \n  tidybayes::add_epred_rvars(peng_mass_hier_brm)\n\npenguin_predicted_hier_avgs |> \n  ggplot(aes(xdist = .epred, y = SppIsland)) + \n  stat_dist_halfeye()+\n  geom_point(aes(x = mass_kg, y = SppIsland), \n             data = penguin_mass_island_rename, \n             position = position_jitter(height = .1), \n             col = \"orange\",\n             inherit.aes = FALSE)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n\nBut we can also make predictions for an entirely new group\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguin_predicted_hier_avgs_NEW <- penguin_mass_island_rename |> \n  select(SppIsland) |> \n  distinct() |> \n  bind_rows(data.frame(SppIsland = \"Adelie_Ireland\")) |> \n  tidybayes::add_epred_rvars(peng_mass_hier_brm, \n                             allow_new_levels = TRUE, \n                             sample_new_levels = \"gaussian\")\n\npenguin_predicted_hier_avgs_NEW |> \n  ggplot(aes(xdist = .epred, y = SppIsland)) + \n  stat_dist_halfeye()+\n  geom_point(aes(x = mass_kg, y = SppIsland), \n             data = penguin_mass_island_rename, \n             position = position_jitter(height = .1), \n             col = \"orange\",\n             inherit.aes = FALSE)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n\n## Observation-level random effects: Mite abundance\n\n### What is the question? \n\nLet's write a model to answer the question:  \n\n**How does the total abundance of the mite community change as water content increases?**  \n\n### Express this in Math\n\nHere's a partially complete model for abundance over time\n\n$$\n  \\begin{align}\n\\text{N}_i &\\sim \\text{Poisson}(e^a) \\\\\na &= \\bar\\beta + \\beta_{\\text{water}} \\cdot \\text{water}_i \\\\\n\\bar\\beta &\\sim \\text{Normal}(?, ?) \\\\\n\\beta_{\\text{water}} &\\sim \\text{Normal}(?, ?) \\\\\n\\end{align}\n$$\n  \n  :::{.callout-tip}\n### EXERCISE \nSimulate from this model, and look at your simulations to decide on a reasonable prior for the data.\n:::\n  \n  :::{.callout-note collapse=\"true\"}\n### SOLUTION\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 30\nwater <- seq(from = -5, to = 5, length.out = n)\n\nb0 <- rnorm(1, mean = log(17), sd = .3)\nb1 <- rnorm(1, mean = 0, sd = .2)\n\nS <- rpois(n, lambda = exp(b0 + b1*water))\nplot(water, S)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-28-1.png){width=672}\n:::\n:::\n\n:::\n  \n  ### Data preparation & visualization\n  \n  First we need to load and prepare the data:\n  \n\n::: {.cell}\n\n```{.r .cell-code}\ndata(mite, package = \"vegan\")\ndata(\"mite.env\", package = \"vegan\")\n\n# combine data and environment\n\nmite_data_long <- mite |> \n  tibble::rownames_to_column(var = \"site_id\") |> \n  bind_cols(mite.env) |> \n  pivot_longer(Brachy:Trimalc2,\n               names_to = \"spp\", values_to = \"abd\")\n```\n:::\n\n\n\nFirst let's transform the mite dataset into a dataframe of total community abundance (N) per site. \nWe'll also standardize the water content while we're at it:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmite_community_abd <- mite_data_long |> \n  group_by(site_id, WatrCont) |> \n  summarize(N = sum(abd)) |>\n  ungroup() |> \n  mutate(water_c = (WatrCont - mean(WatrCont))/100)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`summarise()` has grouped output by 'site_id'. You can override using the\n`.groups` argument.\n```\n\n\n:::\n\n```{.r .cell-code}\nknitr::kable(head(mite_community_abd))\n```\n\n::: {.cell-output-display}\n\n\n|site_id | WatrCont|   N|    water_c|\n|:-------|--------:|---:|----------:|\n|1       |   350.15| 140| -0.6048571|\n|10      |   220.73| 166| -1.8990571|\n|11      |   134.13| 216| -2.7650571|\n|12      |   405.91| 213| -0.0472571|\n|13      |   243.70| 177| -1.6693571|\n|14      |   239.51| 269| -1.7112571|\n\n\n:::\n:::\n\n\nWe get a nice histogram of community abundance, and a clear negative relationship with water volume:\n\n\n::: {.cell layout-ncol=\"2\"}\n\n```{.r .cell-code}\nmite_community_abd |> \n  ggplot(aes(x = N)) + \n  geom_histogram()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-31-1.png){width=672}\n:::\n\n```{.r .cell-code}\nmite_community_abd |> \n  ggplot(aes(x = water_c, y = N)) + \n  geom_point()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-31-2.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## data! \nglimpse(mite_community_abd)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 70\nColumns: 4\n$ site_id  <chr> \"1\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"1…\n$ WatrCont <dbl> 350.15, 220.73, 134.13, 405.91, 243.70, 239.51, 350.64, 321.8…\n$ N        <int> 140, 166, 216, 213, 177, 269, 100, 97, 90, 118, 118, 268, 184…\n$ water_c  <dbl> -0.60485714, -1.89905714, -2.76505714, -0.04725714, -1.669357…\n```\n\n\n:::\n\n```{.r .cell-code}\n## formula!\nmite_bf <- bf(N ~ 1 + water_c, family = poisson(link = \"log\"))\n\n## get the prior\nget_prior(mite_bf, mite_community_abd)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                  prior     class    coef group resp dpar nlpar lb ub tag\n                 (flat)         b                                        \n                 (flat)         b water_c                                \n student_t(3, 4.8, 2.5) Intercept                                        \n       source\n      default\n (vectorized)\n      default\n```\n\n\n:::\n\n```{.r .cell-code}\nmite_prior <- c(\n  prior(normal(2.8, 0.3), class = \"Intercept\"),\n  prior(normal(0, 0.2), class = \"b\")\n)\n\n## run the model! \n\nmite_brm <- brm(mite_bf, data = mite_community_abd, prior = mite_prior, refresh = 100L)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCompiling Stan program...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nTrying to compile a simple C file\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRunning /usr/lib/R/bin/R CMD SHLIB foo.c\nusing C compiler: ‘gcc (Ubuntu 11.4.0-1ubuntu1~22.04.2) 11.4.0’\ngcc -I\"/usr/share/R/include\" -DNDEBUG   -I\"/home/andrew/R/x86_64-pc-linux-gnu-library/4.5/Rcpp/include/\"  -I\"/home/andrew/R/x86_64-pc-linux-gnu-library/4.5/RcppEigen/include/\"  -I\"/home/andrew/R/x86_64-pc-linux-gnu-library/4.5/RcppEigen/include/unsupported\"  -I\"/home/andrew/R/x86_64-pc-linux-gnu-library/4.5/BH/include\" -I\"/home/andrew/R/x86_64-pc-linux-gnu-library/4.5/StanHeaders/include/src/\"  -I\"/home/andrew/R/x86_64-pc-linux-gnu-library/4.5/StanHeaders/include/\"  -I\"/home/andrew/R/x86_64-pc-linux-gnu-library/4.5/RcppParallel/include/\"  -I\"/home/andrew/R/x86_64-pc-linux-gnu-library/4.5/rstan/include\" -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DUSE_STANC3 -DSTRICT_R_HEADERS  -DBOOST_PHOENIX_NO_VARIADIC_EXPRESSION  -D_HAS_AUTO_PTR_ETC=0  -include '/home/andrew/R/x86_64-pc-linux-gnu-library/4.5/StanHeaders/include/stan/math/prim/fun/Eigen.hpp'  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1       -fpic  -g -O2 -ffile-prefix-map=/build/r-base-xupQTd/r-base-4.5.2=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c foo.c -o foo.o\nIn file included from /home/andrew/R/x86_64-pc-linux-gnu-library/4.5/RcppEigen/include/Eigen/Core:19,\n                 from /home/andrew/R/x86_64-pc-linux-gnu-library/4.5/RcppEigen/include/Eigen/Dense:1,\n                 from /home/andrew/R/x86_64-pc-linux-gnu-library/4.5/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22,\n                 from <command-line>:\n/home/andrew/R/x86_64-pc-linux-gnu-library/4.5/RcppEigen/include/Eigen/src/Core/util/Macros.h:679:10: fatal error: cmath: No such file or directory\n  679 | #include <cmath>\n      |          ^~~~~~~\ncompilation terminated.\nmake: *** [/usr/lib/R/etc/Makeconf:202: foo.o] Error 1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nStart sampling\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 1e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.1 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  100 / 2000 [  5%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  300 / 2000 [ 15%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  500 / 2000 [ 25%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  700 / 2000 [ 35%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration:  900 / 2000 [ 45%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1100 / 2000 [ 55%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1300 / 2000 [ 65%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1500 / 2000 [ 75%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1700 / 2000 [ 85%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 1900 / 2000 [ 95%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.011 seconds (Warm-up)\nChain 1:                0.01 seconds (Sampling)\nChain 1:                0.021 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 5e-06 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  100 / 2000 [  5%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  300 / 2000 [ 15%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  500 / 2000 [ 25%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  700 / 2000 [ 35%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration:  900 / 2000 [ 45%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1100 / 2000 [ 55%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1300 / 2000 [ 65%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1500 / 2000 [ 75%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1700 / 2000 [ 85%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 1900 / 2000 [ 95%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.011 seconds (Warm-up)\nChain 2:                0.01 seconds (Sampling)\nChain 2:                0.021 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 4e-06 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.04 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  100 / 2000 [  5%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  300 / 2000 [ 15%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  500 / 2000 [ 25%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  700 / 2000 [ 35%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration:  900 / 2000 [ 45%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1100 / 2000 [ 55%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1300 / 2000 [ 65%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1500 / 2000 [ 75%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1700 / 2000 [ 85%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 1900 / 2000 [ 95%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.011 seconds (Warm-up)\nChain 3:                0.012 seconds (Sampling)\nChain 3:                0.023 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 4e-06 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.04 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  100 / 2000 [  5%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  300 / 2000 [ 15%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  500 / 2000 [ 25%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  700 / 2000 [ 35%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration:  900 / 2000 [ 45%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1100 / 2000 [ 55%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1300 / 2000 [ 65%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1500 / 2000 [ 75%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1700 / 2000 [ 85%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 1900 / 2000 [ 95%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.011 seconds (Warm-up)\nChain 4:                0.01 seconds (Sampling)\nChain 4:                0.021 seconds (Total)\nChain 4: \n```\n\n\n:::\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(mite_brm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: poisson \n  Links: mu = log \nFormula: N ~ 1 + water_c \n   Data: mite_community_abd (Number of observations: 70) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     4.94      0.01     4.92     4.96 1.00     3455     2793\nwater_c       0.02      0.01     0.01     0.04 1.00     4134     2878\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\nPlot the predicted line\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(modelr)\nmite_community_abd |> \n  modelr::data_grid(water_c = seq_range(water_c, n = 7)) |> \n  tidybayes::add_predicted_rvars(mite_brm) |> \n  ggplot(aes(x = water_c, ydist = .prediction)) + \n  stat_dist_lineribbon() + \n  scale_fill_brewer(palette = \"Greens\", direction=-1) + \n  geom_point(aes(x = water_c, y = N),\n             data = mite_community_abd, inherit.aes = FALSE)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-34-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npp_check(mite_brm, type = \"dens_overlay\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nUsing 10 posterior draws for ppc type 'dens_overlay' by default.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-35-1.png){width=672}\n:::\n:::\n\n\n\n## let's do better! \n\n\n::: {.cell}\n\n```{.r .cell-code}\n## data! \nglimpse(mite_community_abd)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 70\nColumns: 4\n$ site_id  <chr> \"1\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"1…\n$ WatrCont <dbl> 350.15, 220.73, 134.13, 405.91, 243.70, 239.51, 350.64, 321.8…\n$ N        <int> 140, 166, 216, 213, 177, 269, 100, 97, 90, 118, 118, 268, 184…\n$ water_c  <dbl> -0.60485714, -1.89905714, -2.76505714, -0.04725714, -1.669357…\n```\n\n\n:::\n\n```{.r .cell-code}\n## formula!\nmite_site_bf <- bf(N ~ 1 + water_c + (1|site_id),\n              family = poisson(link = \"log\"))\n\n## get the prior\nget_prior(mite_site_bf, mite_community_abd)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                  prior     class      coef   group resp dpar nlpar lb ub tag\n                 (flat)         b                                            \n                 (flat)         b   water_c                                  \n student_t(3, 4.8, 2.5) Intercept                                            \n   student_t(3, 0, 2.5)        sd                                    0       \n   student_t(3, 0, 2.5)        sd           site_id                  0       \n   student_t(3, 0, 2.5)        sd Intercept site_id                  0       \n       source\n      default\n (vectorized)\n      default\n      default\n (vectorized)\n (vectorized)\n```\n\n\n:::\n\n```{.r .cell-code}\nmite_site_prior <- c(\n  prior(normal(2.8, 0.3), class = \"Intercept\"),\n  prior(normal(0, 0.2), class = \"b\"),\n  prior(exponential(0.1), class = \"sd\")\n)\n\n## run the model! \n\nmite_site_brm <- brm(mite_site_bf,\n                     data = mite_community_abd, \n                     prior = mite_site_prior, \n                     refresh = 0L, \n                     file = here::here(\"topics/03_one_random_effect/mite_site_brm.rds\"), \n                     file_refit = \"on_change\")\n\nsummary(mite_site_brm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: poisson \n  Links: mu = log \nFormula: N ~ 1 + water_c + (1 | site_id) \n   Data: mite_community_abd (Number of observations: 70) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nMultilevel Hyperparameters:\n~site_id (Number of levels: 70) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.56      0.06     0.46     0.68 1.02      360      719\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     4.70      0.07     4.55     4.83 1.04      157      307\nwater_c      -0.10      0.05    -0.19    -0.01 1.02      290      527\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(modelr)\nmite_community_abd |> \n  modelr::data_grid(water_c = seq_range(water_c, n = 7),\n                    site_id = \"Ireland\") |> \n  tidybayes::add_predicted_rvars(mite_site_brm,\n                                 allow_new_levels = TRUE,\n                                 sample_new_levels = \"gaussian\") |> \n  ggplot(aes(x = water_c, ydist = .prediction)) + \n  stat_dist_lineribbon() + \n  scale_fill_brewer(palette = \"Greens\", direction=-1) + \n  geom_point(aes(x = water_c, y = N),\n             data = mite_community_abd, inherit.aes = FALSE)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-37-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npp_check(mite_site_brm, type = \"dens_overlay\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nUsing 10 posterior draws for ppc type 'dens_overlay' by default.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-38-1.png){width=672}\n:::\n:::\n\n\n## Negative binomial regression\n\nAnother way to model variable count data is via the Negative Binomial distribution. Read more about the [distribution on Wikipedia](https://en.wikipedia.org/wiki/Negative_binomial_distribution), check the way the distribution is [parameterized in brms](https://paulbuerkner.com/brms/articles/brms_families.html#binary-and-count-data-models) , and look at what link family are used via `?brms::brmsfamily` which is also [online here](https://paulbuerkner.com/brms/reference/brmsfamily.html)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## data! \nglimpse(mite_community_abd)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 70\nColumns: 4\n$ site_id  <chr> \"1\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"1…\n$ WatrCont <dbl> 350.15, 220.73, 134.13, 405.91, 243.70, 239.51, 350.64, 321.8…\n$ N        <int> 140, 166, 216, 213, 177, 269, 100, 97, 90, 118, 118, 268, 184…\n$ water_c  <dbl> -0.60485714, -1.89905714, -2.76505714, -0.04725714, -1.669357…\n```\n\n\n:::\n\n```{.r .cell-code}\n## formula!\nmite_negbin_bf <- bf(N ~ 1 + water_c,\n              family = negbinomial(link = \"log\", link_shape = \"log\"))\n\n## prior \nget_prior(mite_negbin_bf, data = mite_community_abd)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                  prior     class    coef group resp dpar nlpar lb ub tag\n                 (flat)         b                                        \n                 (flat)         b water_c                                \n student_t(3, 4.8, 2.5) Intercept                                        \n    inv_gamma(0.4, 0.3)     shape                                0       \n       source\n      default\n (vectorized)\n      default\n      default\n```\n\n\n:::\n\n```{.r .cell-code}\nmite_negbin_prior <- c(\n  prior(normal(2.8, 0.3), class = \"Intercept\"),\n  prior(normal(0, 0.2), class = \"b\"),\n  prior(normal(3, 1), class = \"shape\")\n)\n\nmite_negbin_prior_brm <- brm(mite_negbin_bf,\n                     data = mite_community_abd, \n                     prior = mite_negbin_prior, \n                     refresh = 0L, \n                     file = here::here(\"topics/03_one_random_effect/mite_negbin_prior_brm.rds\"), \n                     file_refit = \"on_change\")\n\nmite_community_abd |> \n  modelr::data_grid(water_c = seq_range(water_c, n = 7)) |> \n  tidybayes::add_predicted_draws(mite_negbin_prior_brm,ndraws = 12) |> \n  ggplot(aes(x = water_c, y = .prediction)) + \n  geom_point() + \n  facet_wrap(~.draw)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-39-1.png){width=672}\n:::\n:::\n\n\n### Exercise\n\nRun a negative binomial regression, and compare to the example above\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}